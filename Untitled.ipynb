{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67d140fa-f7c4-4df3-b606-64f100d5e47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| 'Hello, this is icecream!'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.0\n",
      "2.0.1+cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello, this is icecream!'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n",
    "import math\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(0)\n",
    "from icecream import ic\n",
    "ic(\"Hello, this is icecream!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0955415c-34a6-4799-a90a-9b77a5110bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.row_count=3\n",
    "        self.column_count=3\n",
    "        self.action_size=self.row_count*self.column_count \n",
    "    def get_initial_state(self):\n",
    "        return np.zeros((self.row_count, self.column_count))\n",
    "    def get_next_state(self, state, action, player):\n",
    "        row = action // self.column_count\n",
    "        column = action % self.column_count\n",
    "        state[row,column] = player\n",
    "        return state\n",
    "    def get_valid_moves(self,state):\n",
    "        return (state.reshape(-1) == 0).astype(np.uint8)\n",
    "    def check_win(self, state, action):\n",
    "        if action == None :\n",
    "            return False\n",
    "        row = action // self.column_count\n",
    "        column = action % self.column_count\n",
    "        player = state[row,column] \n",
    "        return(\n",
    "            np.sum(state[row, :])==player*self.column_count\n",
    "            or np.sum(state[:, column])==player*self.row_count\n",
    "            or np.sum(np.diag(state))==player*self.row_count\n",
    "            or np.sum(np.diag(np.flip(state,axis=0)))==player*self.row_count\n",
    "        )\n",
    "    def get_value_and_terminated(self, state, action):\n",
    "        if self.check_win(state,action):\n",
    "            return 1,True\n",
    "        if np.sum(self.get_valid_moves(state))==0: #for draws\n",
    "            return 0, True\n",
    "        return 0, False\n",
    "    def get_opponent(self,player):\n",
    "        return -player\n",
    "\n",
    "    def get_opponent_value(self, value):\n",
    "        return -value\n",
    "\n",
    "    def change_perspective(self, state, player):\n",
    "        return state*player\n",
    "\n",
    "    def get_encoded_state(self, state):\n",
    "        encoded_state = np.stack(\n",
    "            (state == -1, state == 0, state == 1)\n",
    "        ).astype(np.float32)\n",
    "        return encoded_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a00df8b-6192-41f6-a6b3-d59df924f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, game, num_resBlocks, num_hidden):\n",
    "        super().__init__()\n",
    "        self.startBlock = nn.Sequential(\n",
    "        nn.Conv2d(3, num_hidden, kernel_size = 3, padding = 1),\n",
    "        nn.BatchNorm2d(num_hidden),\n",
    "        nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.backBone = nn.ModuleList(\n",
    "        [ResBlock(num_hidden) for i in range(num_resBlocks)]\n",
    "        )\n",
    "\n",
    "        self.policyHead = nn.Sequential(\n",
    "            nn.Conv2d(num_hidden, 32, kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * game.row_count * game.column_count, game.action_size)\n",
    "        )\n",
    "\n",
    "        self.valueHead = nn.Sequential(\n",
    "            nn.Conv2d(num_hidden, 3, kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3 * game.row_count* game.column_count, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.startBlock(x)\n",
    "        for resBlock in self.backBone:\n",
    "            x = resBlock(x)\n",
    "        policy = self.policyHead(x)\n",
    "        value = self.valueHead(x)\n",
    "        return policy, value\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, num_hidden):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding =1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_hidden)\n",
    "        self.conv2 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding =1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_hidden)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13dc7f2d-4338-4608-892b-b083c4dfd215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 1. 0.]]\n",
      "\n",
      " [[1. 1. 0.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 0. 1.]]\n",
      "\n",
      " [[0. 0. 1.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "0.18734028935432434 [0.10597491 0.06834706 0.05474076 0.11852613 0.10499986 0.17755271\n",
      " 0.06796335 0.07478767 0.22710755]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tictactoe = TicTacToe()\n",
    "\n",
    "state = tictactoe.get_initial_state()\n",
    "state = tictactoe.get_next_state(state,2,1)\n",
    "state = tictactoe.get_next_state(state,7,-1)\n",
    "\n",
    "encoded_state = tictactoe.get_encoded_state(state)\n",
    "\n",
    "print(encoded_state)\n",
    "\n",
    "tensor_state = torch.tensor(encoded_state).unsqueeze(0)\n",
    "\n",
    "model = ResNet(tictactoe, 4, 64)\n",
    "\n",
    "policy, value = model(tensor_state)\n",
    "value = value.item()\n",
    "policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "print(value, policy)\n",
    "\n",
    "plt.bar(range(tictactoe.action_size), policy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "33f29125-658d-4e9d-a2ed-a792f8224cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, game, args, state, parent=None, action_taken=None, prior=0):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action_taken = action_taken\n",
    "        self.prior = prior\n",
    "        self.children = []\n",
    "        #self.expandable_moves = game.get_valid_moves(state)\n",
    "\n",
    "        self.visit_count = 0\n",
    "        self.value_sum=0\n",
    "    \n",
    "    def is_fully_expanded(self):\n",
    "        #return np.sum(self.expandable_moves)==0 and len(self.children)>0\n",
    "        return len(self.children)>0\n",
    "\n",
    "    def select(self):\n",
    "        best_child = None\n",
    "        best_ucb = -np.inf\n",
    "\n",
    "        for child in self.children:\n",
    "            ucb = self.get_ucb(child)\n",
    "            if ucb > best_ucb:\n",
    "                best_child = child\n",
    "                best_ucb =ucb\n",
    "        return best_child\n",
    "\n",
    "    def get_ucb(self, child):        #Q(s,a) + Csqrt(ln(n)/n)\n",
    "        if child.visit_count == 0:\n",
    "            q_value = 0\n",
    "        else:\n",
    "            q_value = 1 - ( (child.value_sum / child.visit_count) + 1) / 2    \n",
    "        \n",
    "        return q_value + self.args['C'] * math.sqrt((self.visit_count) / (child.visit_count + 1 ))* child.prior\n",
    "\n",
    "    def expand(self, policy):\n",
    "        for action, prob in enumerate(policy):\n",
    "            if prob >0:\n",
    "                ''' action = np.random.choice(np.where(self.expandable_moves == 1)[0])\n",
    "                self.expandable_moves[action] = 0'''\n",
    "                \n",
    "                child_state = self.state.copy()\n",
    "                child_state = self.game.get_next_state(child_state, action, 1)\n",
    "                child_state = self.game.change_perspective(child_state, player=-1)\n",
    "        \n",
    "                child = Node(self.game, self.args, child_state, self, action,prob)\n",
    "                self.children.append(child)\n",
    "        return child\n",
    "\n",
    "    def simulate(self):\n",
    "        value, is_terminal = self.game.get_value_and_terminated(self.state, self.action_taken)\n",
    "        value = self.game.get_opponent_value(value)\n",
    "\n",
    "        if is_terminal:\n",
    "            return value\n",
    "\n",
    "        rollout_state = self.state.copy()\n",
    "        rollout_player = 1\n",
    "        while True:\n",
    "            valid_moves = self.game.get_valid_moves(rollout_state)\n",
    "            action = np.random.choice(np.where(valid_moves == 1)[0])\n",
    "            rollout_state = self.game.get_next_state(rollout_state, action, rollout_player)\n",
    "            value, is_terminal = self.game.get_value_and_terminated(rollout_state, action)\n",
    "            if is_terminal:\n",
    "                if rollout_player == -1:\n",
    "                    value = self.game.get_opponent_value(value)\n",
    "                return value\n",
    "\n",
    "            rollout_player = self.game.get_opponent(rollout_player)\n",
    "\n",
    "    def backpropagate(self, value):\n",
    "        self.value_sum += value\n",
    "        self.visit_count += 1\n",
    "\n",
    "        value = self.game.get_opponent_value(value)\n",
    "        if self.parent is not None:\n",
    "            self.parent.backpropagate(value)\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, game, args, model):\n",
    "        self.game = game\n",
    "        self.args = args            #for hyperparameters\n",
    "        self.model = model\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def search(self, state):\n",
    "        root = Node(self.game,self.args,state)\n",
    "\n",
    "        for search in range(self.args['num_searches']):\n",
    "            node = root\n",
    "\n",
    "            while node.is_fully_expanded():\n",
    "                node = node.select()       #selection\n",
    "\n",
    "            value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n",
    "            value = self.game.get_opponent_value(value)\n",
    "        \n",
    "            '''if not is_terminal:\n",
    "                node = node.expand()       #expansion\n",
    "                value = node.simulate()    #simulation'''\n",
    "            if not is_terminal:\n",
    "                policy, value = self.model(\n",
    "                    torch.tensor(self.game.get_encoded_state(node.state)).unsqueeze(0)\n",
    "                )\n",
    "                policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
    "                valid_moves = self.game.get_valid_moves(node.state)\n",
    "                policy *= valid_moves\n",
    "                policy /= np.sum(policy)\n",
    "\n",
    "                value = value.item()\n",
    "\n",
    "                node.expand(policy)\n",
    "                \n",
    "            node.backpropagate(value)       #backpropagation\n",
    "            \n",
    "        action_probs = np.zeros(self.game.action_size)\n",
    "        for child in root.children:\n",
    "            action_probs[child.action_taken] = child.visit_count\n",
    "\n",
    "        action_probs /= np.sum(action_probs)\n",
    "        return action_probs\n",
    "            \n",
    "        # return visit_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b54873bb-609d-4142-8704-3ef664dc9eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "valid_moves [0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "1: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[ 0.  1.  0.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "valid_moves [0, 2, 3, 5, 6, 7, 8]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "1: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  1.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[-1.  1.  1.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "valid_moves [3, 5, 6, 7, 8]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "1: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  1.  1.]\n",
      " [ 1. -1.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[-1.  1.  1.]\n",
      " [ 1. -1.  0.]\n",
      " [ 0.  0. -1.]]\n",
      "-1 won\n"
     ]
    }
   ],
   "source": [
    "tictactoe = TicTacToe()\n",
    "player = 1\n",
    "\n",
    "args = {\n",
    "        'C': 2,\n",
    "        'num_searches': 1000\n",
    "}\n",
    "\n",
    "model = ResNet(tictactoe, 4, 64)\n",
    "model.eval()\n",
    "\n",
    "mcts = MCTS(tictactoe, args,model)\n",
    "\n",
    "state = tictactoe.get_initial_state()\n",
    "\n",
    "while True:\n",
    "    print(state)\n",
    "    if player == 1:\n",
    "        valid_moves=tictactoe.get_valid_moves(state)\n",
    "        print(\"valid_moves\",[ i for i in range(tictactoe.action_size) if valid_moves[i]==1])\n",
    "        action = int(input(f\"{player}:\"))\n",
    "    \n",
    "        if valid_moves[action] == 0:\n",
    "            print(\"invalid input\")\n",
    "            continue\n",
    "    else:\n",
    "        neutral_state = tictactoe.change_perspective(state,player)\n",
    "        mcts_probs = mcts.search(neutral_state)\n",
    "        action = np.argmax(mcts_probs)\n",
    "\n",
    "    state = tictactoe.get_next_state(state,action,player)\n",
    "\n",
    "    value, is_terminated = tictactoe.get_value_and_terminated(state,action)\n",
    "\n",
    "    if is_terminated:\n",
    "        print(state)\n",
    "        if value == 1:\n",
    "            print(player, \"won\")\n",
    "        else:\n",
    "            print(\"draw\")\n",
    "        break\n",
    "    player = tictactoe.get_opponent(player)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
